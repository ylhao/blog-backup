---
title: CNN：卷积层和简单的CNN网络结构
categories: 机器学习
tags: 机器学习
mathjax: true
date: 2018-05-24 22:50:04
---

## 卷积层的单层网络结构

卷积神经网络中卷积层的单层网络结构如下：

![](/img/conv_layer1.png)

相比之前的卷积过程，CNN的卷积层单层结构的每个 filter 多了激活函数ReLU和偏置，整个过程与标准的神经网络单层结构非常类似。

## 参数数量的分析
我们来计算一下上图中参数的数目：每个filter有27个权重值，同时每个filter还有1个偏置。所以每个filter有28个参数，我们可以发现，**参数数目与输入图片尺寸无关**，这就不存在图片尺寸过大，造成参数过多的情况。参数数目只由filter决定。

这里对偏置做一个补充，每个fiter只有1个偏置，也就是说每个filter对应的所有神经元共享1个偏置。

## 理解局部连接和权值共享

![](/img/conv_layer2.png)

要理解局部连接和权值共享，我的思路是与全连接神经网络做对比。

首先考虑全连接神经网络，设图片的尺寸为 $6 \times 6$，那么输入层的维度为 $36 \times 1$，再假设隐藏层的神经元个数为 16，也就是说隐藏层的输出的维度为 $16 \times 1$，我们知道全连接神经网络的隐藏层的每个神经元都和输入层的所有神经元相连。如上图的前两幅图所示，隐藏层的红色圆圈代表的神经元和绿色圆圈代表的神经元都和输入层的所有神经元相连，并且红色连线上的权值和绿色线上对应的权值是不共享的。参数总数为 $16 \times 36$。

接着我们考虑使用卷积神经网络，并假设 filter 的尺寸为 $3 \times 3$，不做 padding 处理，步长为 1，filter 的数目为 1。那么我们可以知道卷积层的输出尺寸为 $4 \times 4$。如果我们将卷积层的输出展开，那么我们得到的卷积层的输出维度也为 $16 \times 1$，同时我们也把图片展开，那么输入层的维度也为 $36 \times 1$。如上图的后两幅图所示，我们可以发现每个输出对应的神经元只和输入层的部分神经元相连。并且所有的连接共享一组权值（filter的权值）。参数总数为 $3 \times 3$。

总结下来就是卷积神经网络的卷积层的每个神经元只接收图片的一个局部的像素点的信息作为输入，并且所有的神经元共享的一组权值（filter 的权值），还共用一个偏置。使得卷积层的参数数量只和 fiter 的尺寸和数目有关。

## 一个简单的 CNN 网络结构

![](/img/conv_layer3.png)

上图所示的 CNN 网络结构中除了最后一层为全连层外，其他所有层都为卷积层。并且所有卷积层都没有进行 padding，但各个卷积层的 filter 的尺寸、filter 的数目、步长(stride) 则不一定相同。

通过最后一次卷积，我们得到的输出的维度为 $7 \times 7 \times 40$，我们将其展成一维向量，维度为 1960，然后与一个全连层相连。

随着 CNN 层数的增加，一般输出的高度和宽度都在减小，但输出的“厚度”（通道数对应的维度）一般逐渐增大。

## 参考
1. 深度学习工程师微专业 —— 吴恩达
2. [吴恩达《卷积神经网络》精炼笔记（1）-- 卷积神经网络基础](https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&mid=2247484005&idx=1&sn=2e40be17ad50cc4253a026c37910766a&chksm=976fa7f8a0182eee1fc5f8dde25a87a40f34eb6889cb0927e11f5ce1eaf5ced7fc42950f2b30&scene=21#wechat_redirect)

