---
title: 高斯判别分析
categories: 机器学习
tags: 机器学习
mathjax: true
date: 2018-05-16 11:25:54
---

高斯判别分析（GDA）是一种**生成学习算法**，简单的介绍一下生成学习算法，假设要解决的是一个**二分类问题**，生成学习算法是对这两类的样本（训练集中的）分别建立一个模型，然后看看要分类的样本能更好的匹配哪个模型，我们就说这个样本属于哪一类。
首先需要知道**多变量正态分布**，多变量正态分布是正态分布在多维变量下的扩展，它的参数是一个**均值向量** $\mu \in \mathbb{R}^n$ 和一个**协方差矩阵** $\Sigma \in \mathbb{R}^{n \times n}$，其中 $n$ 是多维随机变量的长度，$\Sigma$ 是对称的并且是半正定矩阵（后文会给出证明），多变量正态分布形式如下：
$$
p(x;\mu,\Sigma) = \frac{1}{(2\pi)^{\frac{n}{2}} \lvert \Sigma \rvert ^ {\frac{1}{2}}}exp (-\frac{1}{2}(x-\mu)^T \Sigma^{-1}(x-\mu))
$$

## 高斯判别分析的假设条件
GDA 针对的问题是输入特征为连续值时的分类问题，在 GDA 中做了以下假设：
1. p(x|y) 属于多变量正态分布
2. y 服从伯努利分布（0-1 分布），这里需要注意我们要解决的是一个二分类问题。


## 高斯判别分析推导
知道了分布，我们就可以写出概率密度：
$$
p(y) = \phi ^y(1-\phi)^{1-y} \\
p(x|y=0) = \frac{1}{(2\pi)^{\frac{n}{2}} \lvert \Sigma \rvert ^ {\frac{1}{2}}}exp (-\frac{1}{2}(x-\mu_0)^T \Sigma^{-1}(x-\mu_0)) \\
p(x|y=1) = \frac{1}{(2\pi)^{\frac{n}{2}} \lvert \Sigma \rvert ^ {\frac{1}{2}}}exp (-\frac{1}{2}(x-\mu_1)^T \Sigma^{-1}(x-\mu_1))
$$

知道了概率密度，我们就可以写出联合概率密度了，也就可以写出数据集的极大似然函数了，同时得到了极大似然函数也就可以得到对应的对数似然函数了，这里直接写出对数似然函数：
$$
\begin{aligned}
l(\phi, \mu_0, \mu_1, \Sigma) =& log \prod_{i=1}^m p(x^{(i)}, y^{(i)};\phi,\mu_0,\mu_1,\Sigma) \\
=& log \prod_{i=1}^m p(x^{(i)}| y^{(i)};\mu_0,\mu_1,\Sigma) p(y^{(i)};\phi)
\end{aligned}
$$

之后求各个参数的极大似然估计：
$$
\phi = \frac{1}{m} \sum_{i=1}^m I(y^{(i)} = 1) \\
\mu_0 = \frac{\sum_{i=1}^m I(y^{(i)} = 0) x^{(i)}}{\sum_{i=1}^m I(y^{(i)} = 0)} \\
\mu_1 = \frac{\sum_{i=1}^m I(y^{(i)} = 1) x^{(i)}}{\sum_{i=1}^m I(y^{(i)} = 1)} \\
\Sigma = \frac{1}{m} \sum_{i=1}^m(x^{(i)} - u_{y^{(i)}})(x^{(i)} - u_{y^{(i)}})^T
$$
至此模型中的参数就都已经估计出来了。

## GDA的后验分布
上面我们得到了 $p(y)$，$p(x|y=0)$，$p(x|y=1)$，那我们可以由贝叶斯公式得到后验概率：
$$
p(y|x) = \frac{p(x|y)p(y)}{p(x)} \\
p(y=1|x)= \frac{p(x|y=1)p(y=1)} {p(x|y=1)p(y=1) + p(x|y=0)p(y=0)} \\
p(y=0|x)= \frac{p(x|y=0)p(y=0)} {p(x|y=0)p(y=0) + p(x|y=1)p(y=1)}
$$

## 高斯判别分析补充
高斯判别分析中不同的高斯分布使用相同的协方差，但是使用不同的均值。

## 高斯判别分析和逻辑回归
高斯判别分析的后验概率分布可以表示成逻辑回归的形式。实际上不仅仅当先验概率分布服从多变量正态分布时可以推导出逻辑斯蒂回归模型，当先验分布属于指数分布族中的任何一个分布（比如泊松分布）时都可以推导出逻辑回归模型。反之，逻辑回归模型的先验概率分布不一定必须得是指数分布族中的成员。因而也说明了逻辑回归模型在建模上的鲁棒性。

结合上面的分析，高斯判别分析对数据分布做了强的假设，认为数据分布是符合高斯分布的（先验概率分布服从多变量正态分布），但逻辑回归并没有做这样的假设，所以逻辑回归的鲁棒性会更好，但如果数据真的服从高斯分布的话，那么 GDA 的效果可能会更好。

## 对协方差矩阵半正定性质的证明
![协方差矩阵是半正定的](/img/gda_1.png)


## 参考
1. [图片来源](https://blog.csdn.net/qcyfred/article/details/71598815/)
2. 斯坦福ML公开课笔记 —— 张雨石
3. 斯坦福机器学习公开课 —— 吴恩达

