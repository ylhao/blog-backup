---
title: BiLSTM介绍
date: 2019-05-13 11:31:04
categories: 机器学习
tags: LSTM
mathjax: true
---

前向的LSTM与后向的LSTM结合成BiLSTM。比如，我们对“我爱中国”这句话进行编码，模型如图1所示。

![双向LSTM编码句子](/img/bilstm_1.png)

前向的$LSTM_L$依次输入“我”，“爱”，“中国”得到三个向量{$h_{L0}$, $h_{L1}$, $h_{L2}$}。后向的$LSTM_R$依次输入“中国”，“爱”，“我”得到三个向量{$h_{R0}$, $h_{R1}$, $h_{R2}$}。最后将前向和后向的隐向量进行拼接得到{[$h_{L0}$, $h_{R2}$], [$h_{L1}$, $h_{R1}$], [$h_{L2}$, $h_{R0}$]}，即{$h_0$, $h_1$, $h_2$}。

对于情感分类任务来说，我们采用的句子的表示往往是[$h_{L2}$, $h_{R2}$]。因为其包含了前向与后向的所有信息，如图2所示。

![1540354954203.png](https://upload-images.jianshu.io/upload_images/9966001-315224dd5c822007.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



前向的LSTM与后向的LSTM结合成BiLSTM。比如，我们对“我爱中国”这句话进行编码，模型如图1所示。

![双向LSTM编码句子](/img/bilstm_1.png)

前向的$LSTM_L$依次输入“我”，“爱”，“中国”得到三个向量{$h_{L0}$, $h_{L1}$, $h_{L2}$}。后向的依次输入“中国”，“爱”，“我”得到三个向量{$h_{R0}$, $h_{R1}$, $h_{R2}$}。最后将前向和后向的隐向量进行拼接得到{[$h_{L0}$, $h_{R2}$], [$h_{L1}$, $h_{R1}$], [$h_{L2}$, $h_{R0}$]}，即{$h_0$, $h_1$, $h_2$}。

对于情感分类任务来说，我们采用的句子的表示往往是[$h_{L2}$, $h_{R2}$]。因为其包含了前向与后向的所有信息，如图2所示。

![拼接向量用于情感分类](/img/bilstm_.png)

## 参考
[BiLSTM介绍及代码实现](https://www.jiqizhixin.com/articles/2018-10-24-13)
