---
title: 对常见的激活函数的总结
categories: 机器学习
tags: 机器学习
mathjax: true
date: 2018-05-19 15:55:12
---
神经网络隐藏层和输出层都需要激活函数（activation function），常见的激活函数主要有：
1. sigmoid 函数
2. tanh 函数
3. ReLU 函数
4. Leaky ReLU 函数

下面来具体介绍下这几个不同的激活函数。

## sigmoid 函数
![sigmoid 函数](/img/activation_function_sigmoid.png)

对应的公式如下：
$$
a = g(z) = \frac{1}{1 + e ^ {-z}} \\
{g}'(z) = g(z)(1-g(z))
$$

## tanh 函数
![tanh 函数](/img/activation_function_tanh.png)

对应的公式如下：
$$
a = g(z) = \frac{e^z - e^{-z}}{e^z + e ^ {-z}} \\
{g}'(z) = 1 - g^2(z)
$$

## ReLU 函数
![ReLU 函数](/img/activation_function_relu.png)

对应的公式如下：
$$
a = g(z) = max(0,z) \\
{g}'(z) = 
\begin{cases}
1 \quad z > 0 \\
0 \quad z < 0 \\
人为指定为 1 \quad z = 0
\end{cases}
$$

## Leaky ReLU 函数
![Leaky ReLU 函数](/img/activation_function_leaky_relu.png)

对应的公式如下：
$$
a = g(z) = max(0.01z, z) \\
{g}'(z) = 
\begin{cases}
1 \quad z > 0 \\
0.01 \quad z < 0 \\
人为指定为 1 \quad z = 0
\end{cases}
$$

## 应该注意的问题
首先对于 ReLU 函数，在 $z = 0$ 时是不可微的，但可以人为的给定一个值，人为指定当 $z = 0$ 时，ReLU 函数的导数为 0 或 1 都可以。对于 Leaky ReLU 函数也是一样的。

对于隐藏层的激活函数，一般来说，tanh 函数要比 sigmoid 函数表现更好一些，因为 tanh 函数的取值范围在 $[-1, 1]$ 之间，相当于将隐藏层的输出限定在了 $[-1, 1]$ 之间，而 sigmoid 函数的输出在 $[0,1]$ 之间，相当于将隐藏层的输出限定在了 $[0,1]$ 之间，可见 tanh 函数可令隐藏层的输出在 0 值附近均匀分布，起到了一定的将数据中心化的作用。所以一般来说，在隐藏层，tanh 函数要比 sigmoid 函数的表现好一些。

如果要解决的是一个分类问题，那么在输出层，一般要选择 sigmoid 函数。

对于 sigmoid 函数和 tanh 函数来说，当 $\lvert z \rvert$ 很大时，激活函数的斜率（梯度）很小。因此，在这个区域内，梯度下降算法会运行得比较慢。在实际应用中，应尽量避免使 $\lvert z \rvert$ 落在这个区域，应该使 $\lvert z \rvert$ 尽可能的限定在 0 值附近，提高梯度下降法的效率。

为了弥补 sigmoid 函数和 tanh 函数的这个缺陷，就出现了 ReLU 激活函数。ReLU 激活函数在 $z>0$ 时梯度始终为 1，在 $z < 0$ 时梯度始终为 0，$z=0$ 时的梯度可以当成 1 也可以当成 0，实际使用中并不影响。对于隐藏层，选择 ReLU 作为激活函数能够保证 $z > 0$ 时梯度始终为 1，从而提高神经网络梯度下降算法运算速度。但当 $z<0$ 时，存在梯度为 0 的缺点，实际应用中，这个缺点影响不是很大。为了弥补这个缺点，出现了 Leaky ReLU 激活函数，能够保证 $z<0$ 时梯度不为0。

## 激活函数特点和作用
激活函数必须是非线性函数而不能是线性函数，因为线性函数的组合仍然是线性函数，这样就不可能给模型引入非线性因素，也就不可能解决非线性问题。

激活函数可以为模型引入非线性因素，从而可以解决非线性问题，同时再加上多个神经元之间存在组合的情况，那么模型的表达能力就更强了。

## 参考
1. 深度学习工程师微专业（01.神经网络和深度学习）—— 吴恩达
2. [吴恩达《神经网络与深度学习》精炼笔记（4）-- 浅层神经网络](https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&mid=2247483918&idx=1&sn=b2e0b086243b464f8ca32a938ff9fcfe&chksm=976fa793a0182e856784071cd5a84476cb5c8c98e12415bc3eef6ae8bd0bf4dcdb6e4927cfec&scene=21#wechat_redirect)

